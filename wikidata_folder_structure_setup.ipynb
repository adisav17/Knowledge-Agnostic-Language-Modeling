{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw3YSYRDYRm9i3n4VGiNY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adisav17/ontology-driven-language-modeling/blob/main/wikidata_folder_structure_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_ysnBZwhNFg",
        "outputId": "a1bd4976-e110-462c-b034-66a9cde35fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ontology-driven-language-modeling'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 135 (delta 22), reused 121 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (135/135), 41.02 KiB | 2.93 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/adisav17/ontology-driven-language-modeling.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"adisav17@gmail.com\"\n",
        "!git config --global user.name \"adisav17\""
      ],
      "metadata": {
        "id": "knsIHkY8i6bP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ontology-driven-language-modeling\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuAq3oSmjg8I",
        "outputId": "8fd49fc3-11b8-433f-efde-313f6666f01c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ontology-driven-language-modeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "access_token = getpass('Enter token: ')\n",
        "!git remote set-url origin https://{access_token}@github.com/adisav17/ontology-driven-language-modeling.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef96-w8djoYR",
        "outputId": "5fed63ab-3592-4b26-c04a-a4cacc11a9c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git mv knowledge knowledge_beta\n"
      ],
      "metadata": {
        "id": "yJqS3_On5e8g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Renamed folder\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMCA_yb35roG",
        "outputId": "7020554d-7e11-4c2b-958e-119955515893"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 82dc6f9] Renamed folder\n",
            " 58 files changed, 0 insertions(+), 0 deletions(-)\n",
            " rename {knowledge => knowledge_beta}/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/concerts/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/concerts/concerts.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/events/conferences/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/conferences/conferences.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/events/festivals/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/festivals/festivals.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/events/natural_disasters/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/natural_disasters/natural_disasters.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/events/political_elections/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/political_elections/political_elections.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/events/protests/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/protests/protests.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/events/sports_tournaments/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/sports_tournaments/sports_tournaments.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/events/trade_shows/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/events/trade_shows/trade_shows.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/geographical_locations/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/geographical_locations/cities/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/geographical_locations/cities/cities.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/geographical_locations/countries/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/geographical_locations/countries/countries.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/corporations/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/corporations/corporations.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/educational_institutions/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/educational_institutions/educational_institutions.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/government_agencies/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/government_agencies/federal/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/government_agencies/federal/federal.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/government_agencies/local/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/government_agencies/state/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/media_outlets/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/media_outlets/media_outlets.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/non_profit_organizations/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/organizations/non_profit_organizations/non_profit_organizations.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/artists/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/artists/artists.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/athletes/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/athletes/athletes.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/doctors/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/doctors/doctors.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/engineers/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/engineers/engineers.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/entrepreneurs/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/entrepreneurs/entrepreneurs.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/journalists/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/journalists/journalists.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/lawyers/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/lawyers/lawyers.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/politicians/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/politicians/politicians.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/scientists/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/scientists/scientists.txt (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/teachers/.gitkeep (100%)\n",
            " rename {knowledge => knowledge_beta}/professions/teachers/teachers.txt (100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FixtUcld5uJH",
        "outputId": "60aaaadb-bfd6-489c-8d15-276b2b63eda6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 3, done.\n",
            "Counting objects:  33% (1/3)\rCounting objects:  66% (2/3)\rCounting objects: 100% (3/3)\rCounting objects: 100% (3/3), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  50% (1/2)\rCompressing objects: 100% (2/2)\rCompressing objects: 100% (2/2), done.\n",
            "Writing objects:  50% (1/2)\rWriting objects: 100% (2/2)\rWriting objects: 100% (2/2), 247 bytes | 247.00 KiB/s, done.\n",
            "Total 2 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas:   0% (0/1)\u001b[K\rremote: Resolving deltas: 100% (1/1)\u001b[K\rremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/adisav17/ontology-driven-language-modeling.git\n",
            "   c53154d..82dc6f9  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a nested dictionary with an additional layer for subtypes to represent the folder structure\n",
        "folder_structure = {\n",
        "    \"knowledge\": {\n",
        "        \"organizations\": {\n",
        "            \"government_agencies\": {\n",
        "                \"federal\": [],\n",
        "                \"state\": [],\n",
        "                \"local\": []\n",
        "            },\n",
        "            \"corporations\": [],\n",
        "            \"non_profit_organizations\": [],\n",
        "            \"educational_institutions\": [],\n",
        "            \"media_outlets\": []\n",
        "        },\n",
        "        \"professions\": {\n",
        "            \"politicians\": [],\n",
        "            \"doctors\": [],\n",
        "            \"lawyers\": [],\n",
        "            \"engineers\": [],\n",
        "            \"journalists\": [],\n",
        "            \"teachers\": [],\n",
        "            \"scientists\": [],\n",
        "            \"artists\": [],\n",
        "            \"entrepreneurs\": [],\n",
        "            \"athletes\": []\n",
        "        },\n",
        "        \"events\": {\n",
        "            \"natural_disasters\": [],\n",
        "            \"political_elections\": [],\n",
        "            \"sports_tournaments\": [],\n",
        "            \"concerts\": [],\n",
        "            \"trade_shows\": [],\n",
        "            \"protests\": [],\n",
        "            \"conferences\": [],\n",
        "            \"festivals\": []\n",
        "        },\n",
        "        \"geographical_locations\": {\n",
        "            \"cities\": [],\n",
        "            \"countries\": []\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eDcT1poIjvsr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create directories recursively\n",
        "def create_directories(path, structure):\n",
        "    for key, value in structure.items():\n",
        "        new_path = f\"{path}/{key}\"\n",
        "        !mkdir -p {new_path}\n",
        "        if isinstance(value, dict):\n",
        "            create_directories(new_path, value)\n",
        "\n"
      ],
      "metadata": {
        "id": "1k7r17KI0O6K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories\n",
        "create_directories(\"/content/ontology-driven-language-modeling\", folder_structure)"
      ],
      "metadata": {
        "id": "mfdvFE220Vzj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create .gitkeep files recursively in each directory\n",
        "def create_gitkeep_files(path, structure):\n",
        "    for key, value in structure.items():\n",
        "        new_path = f\"{path}/{key}\"\n",
        "        !touch {new_path}/.gitkeep\n",
        "        if isinstance(value, dict):\n",
        "            create_gitkeep_files(new_path, value)\n",
        "\n",
        "# Creating .gitkeep files\n",
        "create_gitkeep_files(\"/content/ontology-driven-language-modeling\", folder_structure)\n"
      ],
      "metadata": {
        "id": "wBwkjCEA0YOc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"Create updated folder structure with subtypes\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7QmWuWn01h0",
        "outputId": "dc40ad4d-4480-48db-cbbb-82c2d218b0c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SPARQLWrapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LldFFocZ3dtB",
        "outputId": "e8ad1e88-4bd6-4c7c-884b-227959ca8a61"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting rdflib>=6.1.1 (from SPARQLWrapper)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->SPARQLWrapper)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
            "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")"
      ],
      "metadata": {
        "id": "huKnWKdh3fYA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparql.setQuery(\"\"\"\n",
        "SELECT ?country ?countryLabel WHERE {\n",
        "  ?country wdt:P31 wd:Q6256.\n",
        "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
        "}\n",
        "LIMIT 100\n",
        "\"\"\")\n",
        "sparql.setReturnFormat(JSON)\n",
        "countries = sparql.query().convert()"
      ],
      "metadata": {
        "id": "1P40C13i5P05"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_names = [result['countryLabel']['value'] for result in countries['results']['bindings']]\n"
      ],
      "metadata": {
        "id": "mr5fBq2h5T66"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_names[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWZ2C9S96y09",
        "outputId": "3656a104-5fc9-431b-c3cc-17d28a6d57d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Canada', 'Japan', 'Norway', 'England', 'Scotland']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'India' in country_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfCIrZVK6641",
        "outputId": "2551d199-f238-4f81-bb14-863cef4e5feb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the folder where the file needs to be saved\n",
        "file_path = \"/content/ontology-driven-language-modeling/knowledge/geographical_locations/countries/countries.txt\""
      ],
      "metadata": {
        "id": "dNvSQw4Y50c0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, \"w\") as file:\n",
        "    for country in country_names:\n",
        "        file.write(country + '\\n')"
      ],
      "metadata": {
        "id": "giGCE_w-52hn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add -A\n",
        "!git commit -m \"Added a list of countries to geographical_locations/countries\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDFm38an5-N0",
        "outputId": "736b4d27-c152-42b4-9db2-feaee63df5ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_query_mapping = {\n",
        "    \"knowledge/organizations/government_agencies/federal\": \"wd:Q327333\",  # This is a general ID for government agencies, further filter might be needed\n",
        "    \"knowledge/organizations/corporations\": \"wd:Q6881511\",        # Business Entity, including companies\n",
        "    \"knowledge/organizations/non_profit_organizations\": \"wd:Q163740\",  # Non-Profit Organization\n",
        "    \"knowledge/organizations/educational_institutions\": \"wd:Q3918\",  # Educational Institution (School)\n",
        "    \"knowledge/organizations/media_outlets\": \"wd:Q11032\",          # Media Organization\n",
        "    \"knowledge/professions/politicians\": \"wd:Q82955\",              # Politician\n",
        "    \"knowledge/professions/doctors\": \"wd:Q39631\",                  # Physician\n",
        "    \"knowledge/professions/lawyers\": \"wd:Q40348\",                  # Lawyer\n",
        "    \"knowledge/professions/engineers\": \"wd:Q81096\",                # Engineer\n",
        "    \"knowledge/professions/journalists\": \"wd:Q1930187\",            # Journalist\n",
        "    \"knowledge/professions/teachers\": \"wd:Q37226\",                 # Teacher\n",
        "    \"knowledge/professions/scientists\": \"wd:Q901\",                 # Scientist\n",
        "    \"knowledge/professions/artists\": \"wd:Q483501\",                 # Artist\n",
        "    \"knowledge/professions/entrepreneurs\": \"wd:Q131524\",           # Entrepreneur\n",
        "    \"knowledge/professions/athletes\": \"wd:Q2066131\",               # Athlete\n",
        "    \"knowledge/events/natural_disasters\": \"wd:Q8065\",              # Natural Disaster\n",
        "    \"knowledge/events/political_elections\": \"wd:Q40231\",           # Election\n",
        "    \"knowledge/events/sports_tournaments\": \"wd:Q27020041\",         # Sports Competition\n",
        "    \"knowledge/events/concerts\": \"wd:Q182945\",                     # Concert\n",
        "    \"knowledge/events/trade_shows\": \"wd:Q56245015\",                # Trade Fair\n",
        "    \"knowledge/events/protests\": \"wd:Q36484\",                      # Protest\n",
        "    \"knowledge/events/conferences\": \"wd:Q2020153\",                 # Conference\n",
        "    \"knowledge/events/festivals\": \"wd:Q220505\",                    # Festival\n",
        "    \"knowledge/geographical_locations/countries\": \"wd:Q6256\",      # Country\n",
        "    \"knowledge/geographical_locations/cities\": \"wd:Q515\",          # City\n",
        "}\n"
      ],
      "metadata": {
        "id": "Br9L8Qqx-EKW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWj1RWp4eMm2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from SPARQLWrapper import SPARQLWrapper, JSON"
      ],
      "metadata": {
        "id": "AnC8IMXM-GZE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to fetch data from Wikidata and save to a file\n",
        "def fetch_and_save_data(folder, entity_id):\n",
        "    # Set up the SPARQL query\n",
        "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
        "\n",
        "    #query = f\"\"\"\n",
        "    #SELECT ?item ?itemLabel WHERE {{\n",
        "    #  ?item wdt:P31 {entity_id}.\n",
        "    #  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
        "    #}}\n",
        "    #LIMIT 100\n",
        "    #\"\"\"\n",
        "\n",
        "    query = f\"\"\"\n",
        "    SELECT ?item ?itemLabel ?sitelinks WHERE {{\n",
        "     ?item wdt:P31 {entity_id}.\n",
        "     SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
        "\n",
        "     # Get the count of sitelinks\n",
        "     OPTIONAL {{ ?item wikibase:sitelinks ?sitelinks. }}\n",
        "\n",
        "     # You can even add more OPTIONAL clauses to gather additional information if needed\n",
        "     }}\n",
        "     ORDER BY DESC(?sitelinks)  # Ordering by the count of sitelinks in descending order\n",
        "     LIMIT 100\n",
        "     \"\"\"\n",
        "\n",
        "    sparql.setQuery(query)\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    results = sparql.query().convert()\n",
        "\n",
        "    # Extract entity names\n",
        "    entity_names = [result['itemLabel']['value'] for result in results['results']['bindings']]\n",
        "\n",
        "    # File path\n",
        "    file_path = f\"/content/ontology-driven-language-modeling/{folder}/{folder.split('/')[-1]}.txt\"\n",
        "\n",
        "    # Save entity names to the file\n",
        "    with open(file_path, \"w\") as file:\n",
        "        for name in entity_names:\n",
        "            file.write(name + '\\n')\n"
      ],
      "metadata": {
        "id": "E5p5mOHl-U2J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "# Function to fetch data from Wikidata and save to a file with improved error handling and retries\n",
        "def fetch_and_save_data_improved(folder, entity_id, max_retries=5, retry_delay=15):\n",
        "    # Initialize SPARQL\n",
        "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
        "\n",
        "    # SPARQL query to fetch items and their labels, along with sitelinks count (if available)\n",
        "    query = f\"\"\"\n",
        "    SELECT ?item ?itemLabel ?sitelinks WHERE {{\n",
        "      ?item wdt:P31 {entity_id}.\n",
        "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
        "      OPTIONAL {{ ?item wikibase:sitelinks ?sitelinks. }}\n",
        "    }}\n",
        "    ORDER BY DESC(?sitelinks)\n",
        "    LIMIT 100\n",
        "    \"\"\"\n",
        "\n",
        "    sparql.setQuery(query)\n",
        "    sparql.setReturnFormat(JSON)\n",
        "\n",
        "    retries = 0\n",
        "\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            # Execute the SPARQL query\n",
        "            results = sparql.query().convert()\n",
        "\n",
        "            # Extract entity names\n",
        "            entity_names = [result['itemLabel']['value'] for result in results['results']['bindings']]\n",
        "\n",
        "            # File path to save the results\n",
        "            file_path = f\"/content/ontology-driven-language-modeling/{folder}/{folder.split('/')[-1]}.txt\"\n",
        "\n",
        "            # Save entity names to the file\n",
        "            with open(file_path, \"w\") as file:\n",
        "                for name in entity_names:\n",
        "                    file.write(name + '\\n')\n",
        "\n",
        "            print(f\"Data successfully saved to {file_path}\")\n",
        "            break  # Exit the loop if the data is successfully fetched and saved\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {type(e).__name__}: {e}. Retrying in {retry_delay} seconds...\")\n",
        "            time.sleep(retry_delay)\n",
        "            retries += 1\n",
        "\n",
        "    if retries >= max_retries:\n",
        "        print(f\"Failed to fetch data after {max_retries} retries. Please check the SPARQL query and endpoint availability.\")\n",
        "\n",
        "# Test with an example call\n",
        "# fetch_and_save_data_improved(\"knowledge/geographical_locations/countries\", \"wd:Q6256\")\n"
      ],
      "metadata": {
        "id": "b6B-6flEleW_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Iterate over the folder-query mapping to fetch data and save to files\n",
        "for folder, entity_id in folder_query_mapping.items():\n",
        "\n",
        "    fetch_and_save_data_improved(folder, entity_id)\n",
        "    #time.sleep(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKxf5PWb-nss",
        "outputId": "0c65da3a-5401-41e2-8b03-04b35daa60c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/organizations/government_agencies/federal/federal.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/organizations/corporations/corporations.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/organizations/non_profit_organizations/non_profit_organizations.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/organizations/educational_institutions/educational_institutions.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/organizations/media_outlets/media_outlets.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/politicians/politicians.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/doctors/doctors.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/lawyers/lawyers.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/engineers/engineers.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/journalists/journalists.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/teachers/teachers.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/scientists/scientists.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/artists/artists.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/entrepreneurs/entrepreneurs.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/professions/athletes/athletes.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/natural_disasters/natural_disasters.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/political_elections/political_elections.txt\n",
            "An error occurred: EndPointInternalError: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
            "\n",
            "Response:\n",
            "b'SPARQL-QUERY: queryStr=\\n    SELECT ?item ?itemLabel ?sitelinks WHERE {\\n      ?item wdt:P31 wd:Q27020041.\\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n      OPTIONAL { ?item wikibase:sitelinks ?sitelinks. }\\n    }\\n    ORDER BY DESC(?sitelinks)\\n    LIMIT 100\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:320)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:82)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:119)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'. Retrying in 15 seconds...\n",
            "An error occurred: EndPointInternalError: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
            "\n",
            "Response:\n",
            "b'SPARQL-QUERY: queryStr=\\n    SELECT ?item ?itemLabel ?sitelinks WHERE {\\n      ?item wdt:P31 wd:Q27020041.\\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n      OPTIONAL { ?item wikibase:sitelinks ?sitelinks. }\\n    }\\n    ORDER BY DESC(?sitelinks)\\n    LIMIT 100\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:320)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:82)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:119)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'. Retrying in 15 seconds...\n",
            "An error occurred: EndPointInternalError: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
            "\n",
            "Response:\n",
            "b'SPARQL-QUERY: queryStr=\\n    SELECT ?item ?itemLabel ?sitelinks WHERE {\\n      ?item wdt:P31 wd:Q27020041.\\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n      OPTIONAL { ?item wikibase:sitelinks ?sitelinks. }\\n    }\\n    ORDER BY DESC(?sitelinks)\\n    LIMIT 100\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:320)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:82)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:119)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'. Retrying in 15 seconds...\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/sports_tournaments/sports_tournaments.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/concerts/concerts.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/trade_shows/trade_shows.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/protests/protests.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/conferences/conferences.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/events/festivals/festivals.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/geographical_locations/countries/countries.txt\n",
            "Data successfully saved to /content/ontology-driven-language-modeling/knowledge/geographical_locations/cities/cities.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add -A\n",
        "!git commit -m \"Added sample entity data to respective folders\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7TBIg8F_OLS",
        "outputId": "0e649a3a-b28c-4e18-927f-32b8643cac79"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main c53154d] Added sample entity data to respective folders\n",
            " 20 files changed, 1109 insertions(+), 1109 deletions(-)\n",
            " rewrite knowledge/events/festivals/festivals.txt (65%)\n",
            " rewrite knowledge/events/political_elections/political_elections.txt (88%)\n",
            " rewrite knowledge/events/sports_tournaments/sports_tournaments.txt (99%)\n",
            " rewrite knowledge/organizations/corporations/corporations.txt (82%)\n",
            " rewrite knowledge/organizations/educational_institutions/educational_institutions.txt (89%)\n",
            " rewrite knowledge/organizations/government_agencies/federal/federal.txt (79%)\n",
            " rewrite knowledge/organizations/media_outlets/media_outlets.txt (75%)\n",
            " rewrite knowledge/organizations/non_profit_organizations/non_profit_organizations.txt (93%)\n",
            "Enumerating objects: 95, done.\n",
            "Counting objects: 100% (95/95), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (48/48), done.\n",
            "Writing objects: 100% (48/48), 14.31 KiB | 2.04 MiB/s, done.\n",
            "Total 48 (delta 10), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (10/10), completed with 10 local objects.\u001b[K\n",
            "To https://github.com/adisav17/ontology-driven-language-modeling.git\n",
            "   1a99587..c53154d  main -> main\n"
          ]
        }
      ]
    }
  ]
}